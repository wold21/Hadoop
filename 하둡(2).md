- 하둡에 관한 로그는 logs에 있음.
- yarn의 로그 파일은 cd에 hdfs-data -> hadoop -> data -> yarn -> logs에 있다
- C라는 패키지를 설치할때 C는 B를 필요로 하고 B는 A를 필요로 하기 때문에
- 다 받아줘야한다. 근데 이 관계가 많을 경우에는 불편하기 때문에 라이브러리 관리를 해주는 프로그램이 있으면 좋겠다.
- 디펜던시 파일까지 다 찾아주는 툴이 있으면 좋겠다 싶어서 만든 프로그램
- Maven
- Qrradle

## wordcount를 직접 구현해보자.

### 1. 먼저 자바에서 Maven프로젝트 작성

- group id
- artifect id
- version 0.0.1
  - 
- packaging 
  - jar
- JRE Target을 하둡시스템과 맞춰줘야한다.
  - 여기선 -14

~~~ java
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
  <modelVersion>4.0.0</modelVersion>
  <groupId>com.tazomaven</groupId>
  <artifactId>com.tazomaven</artifactId>
  <version>0.0.1</version>  	
	<build>
  		<plugins>
  			<plugin>
  				<groupId>org.apache.maven.plugins</groupId>
  				<artifactId>maven-compiler-plugin</artifactId>
  				<version>3.6.1</version>
  				<configuration>
  					<source>1.8</source>
  					<target>1.8</target>
  				</configuration>
  			</plugin>
  		</plugins>
  	</build>
  	
  	<dependencies>
  // 1번.
	<dependency>
    	<groupId>org.apache.hadoop</groupId>
    	<artifactId>hadoop-common</artifactId>
    	<version>2.7.2</version>
	</dependency>
  
	// 2번.
	<dependency>
    	<groupId>org.apache.hadoop</groupId>
    	<artifactId>hadoop-mapreduce-client-core</artifactId>
    	<version>2.7.2</version>
	</dependency>
	</dependencies>
~~~

작성해준다.

dependencies로 감싸진 부분은 https://mvnrepository.com/에서 코드를 따옴.

1. Apache Hadoop Common
2. Apache Hadoop MapReduce Core



### # 자바 설정 -> 제너럴 -> 워크스페이스 -> other (UTF-8)을 

### # 해놓으면 다른 곳에 옮겨도 한글이나 언어들이 깨지지 않는다.



새롭게 클래스를 만든다

#### wordcount

~~~ java
package com.tazomaven.map;

import java.io.IOException;
import java.util.StringTokenizer;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class WordCountMapper extends Mapper<LongWritable, Text, Text, IntWritable> {
	
	// mapping을 하면 항상 상수값이 1이기 때문에(왜냐하면 값을 모두 스플릿하고 매핑하면 그 갯수는 항상 1이다.)
	// 그 값을 먼저 잡아준다.
	private final static IntWritable one = new IntWritable(1);
	
	// text를 담을 객체를 하나 생성해준다. 
	private Text word = new Text();

	// 그리고 맵핑 해주기 위해. 
	// 상속받는 Mapper에 있는 map 함수를 사용할 것이다.
	@Override
	protected void map(LongWritable key, Text value, 
			Mapper<LongWritable, Text, Text, IntWritable>.Context context)
			throws IOException, InterruptedException {
		
		StringTokenizer strToken = new StringTokenizer(value.toString());
		while(strToken.hasMoreTokens()) {
			word.set(strToken.nextToken());
			context.write(word, one);
		}			
	}	
}
~~~



- Mapper<LongWritable, Text, Text, IntWritable>
  - 라인넘버 값, 라인, 단어, 갯수
- StringTokenizer
  - 단어를 나눠준다, 기준이 없으면 블랭크 기준.



#### reduce

그리고 자바에서 maven

타겟 폴더에 잡 파일을 만들어 준다.



~~~ 
 bin/yarn jar /mnt/Share/java/com.tazomaven-0.0.1.jar com.tazomaven.driver.WordCount word-input2 word-output2
~~~

- 맨처음에 

