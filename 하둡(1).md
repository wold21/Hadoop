# Hadoop



## 기기 간 키 인증

- 기기끼리 통신할 때 로그인 과정이 있으면 좋지 않다.
- 그렇기에 서로만 통신 가능한 키를 쥐어준다.
- namenode와 secondary node, data node 등등 모두 각자가 기준이 되어 키를 주고 키를 받아야한다.

### namenode에서 ssh 키 생성

- ssh-keygen -t rsa
- Generating public/private rsa key pair.
  Enter file in which to save the key (/home/companion_tazo/.ssh/id_rsa):
- Created directory '/home/companion_tazo/.ssh'.
  Enter passphrase (empty for no passphrase):
- Enter same passphrase again:
- Your identification has been saved in /home/companion_tazo/.ssh/id_rsa.
  Your public key has been saved in /home/companion_tazo/.ssh/id_rsa.pub.
  The key fingerprint is:
  SHA256:X4uhoG/fr6pyXpeYIbnS3oEdWRR2HgR3K/AxS6uQvRU companion_tazo@hadoopnode01
  The key's randomart image is:
  +---[RSA 2048]----+
  |          *+E .  |
  |         = B O . |
  |        o o B .  |
  |       . + + .   |
  |      + S + .    |
  |     o * B = .   |
  |    o + B = .    |
  |    .+oo +       |
  |     ==o+.oo.    |
  +----[SHA256]-----+
- id_rsa 나의 키
- id_rsa.pub. 상대방에게 넘겨 줄 키



#### 키 복사

- ssh-copy-id -i /home/companion_tazo/.ssh/id_rsa.pub companion_tazo@hadoopnode02

- /usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/home/companion_tazo/.ssh/id_rsa.pub"
  The authenticity of host 'hadoopnode02 (10.0.2.15)' can't be established.
  ECDSA key fingerprint is SHA256:2Ux4nq+Gfg+EskX0056mpeaFkZK96SS+321J5nQrS/I.
  ECDSA key fingerprint is MD5:cc:75:ae:37:99:32:bc:66:af:af:34:8c:69:d5:\cd:a7.
  Are you sure you want to continue connecting (yes/no)?  y
  Please type 'yes' or 'no': yes

- /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
  /usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
  companion_tazo@hadoopnode02's password:

  Number of key(s) added: 1

  Now try logging into the machine, with:   "ssh 'companion_tazo@hadoopnode02'"
  and check to make sure that only the key(s) you wanted were added.



#### 다음 단계

- 홈 디렉토리에 가서 다운 받아 놓은 하둡압축을 풀고 심볼릭 링크 hadoop으로 만들어 준 뒤
- vi etc/hadoop/hadoop-env.sh에가서 자바 환경 변수 확인

- export HADOOP_PID_DIR= 의 경로를 압축 푼 폴더 안에 pids 폴더를 만들고 그 경로를
- 넣어준다. 저장.

- masters 파일을 만듬(etc/hadoop 위치임), 세컨더리 네임노드의 호트스명을 기술해 주는 곳.
- 여기선 실습이기 때문에 만들어 놓았던 01(원래는 02)을 적으면 된다.

- slaves라는 파일은 데이터 노드의 이름(호스트 네임)을 적어줘야하는 부분이다.



- core-site.xml에 들어가서 <configuration> 사이에다가 작성해준다.

- <property>
      <name>fs.defaultFS</name>
      <value>hdfs://hadoopnode01:9000</value>
  </property>

  <property>
      <name>hadoop.tmp.dir</name>
      <value>/home/companion_tazo/hdfs-data/hadoop/tmp</value>
  </property>

- 임시 파일 폴더를 두번째 property에서 설정해준다.

- 안해주면 리눅스 디폴트 tmp폴더에 쌓여서 리눅스 자체의 임시 파일들과 겹치기 떄문에

- 따로 만들어 주어야 한다.

- 원하는 위치에 tmp폴더를 만들어주고 그 경로를 써준다.



- hdfs-site.xml에 들어가서 <configuration> 사이에 작성해준다.

-     <property>
          <name>dfs.replication</name>
          <value>1</value>
      </property>
      
      <property>
          <name>dfs.namenode.checkpoint.dir</name>
          <value>/home/companion_tazo/hdfs-data/hadoop/data/name-secondary</value>
      </property>
      
      <property>
          <name>dfs.secondary.http.address</name>
          <value>hadoopnode01:50090</value>
      </property>
      
      <property>
          <name>dfs.http.address</name>
          <value>hadoopnode01:50070</value>
      </property>
      
      <property>
          <name>dfs.namenode.name.dir</name>
          <value>/home/companion_tazo/hdfs-data/hadoop/data/namenode</value>
      </property>
      
      <property>
          <name>dfs.datanode.data.dir</name>
          <value>/home/companion_tazo/hdfs-data/hadoop/data/datanode</value>
      </property>
  1. 데이터 노드 안에 들어있는 블럭 갯수 설정.
  2. checkpoint 저장소
  3. 세컨더리를 웹으로 보기 위한 주소 설정
  4. 네임 노드 웹으로 보기 위한 주소 설정
  5. 각 노드가 해야할 저장소 설정.
  6. 5번과 똑같음



- mapred-site.xml.template 복사하기.

  - 위치는 hadoop-2.7.2/etc/hadoop/mapred-site.xml.template
  - mapred-site.xml으로 이름 바꿈.

- 그것을 vi로 연다.

-     <property>
          <name>mapreduce.framework.name</name>
          <value>yarn</value>
      </property>
      
      <property>
          <name>yarn.app.mapreduce.am.env</name>
          <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
      </property>
      
      <property>
          <name>mapreduce.map.env</name>
          <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
      </property>
      
      <property>
          <name>mapreduce.reduce.env</name>
          <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
      </property>

- yarn으로 설치하기 위해 yarn으로 지정해줬다.

- hdfs를 쓸 때 리소스 관리를 효율적으로 하기위해서 발명.



-  vi etc/hadoop/yarn-site.xml

-     <property>
          <name>yarn.nodemanager.aux-services</name>
          <value>mapreduce_shuffle</value>
      </property>
      
      <property>
          <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
          <value>org.apache.hadoop.mapred.ShuffleHandler</value>
      </property>
      
      <property>
          <name>yarn.nodemanager.local-dirs</name>
          <value>/home/companion_tazo/hdfs-data/hadoop/data/yarn/local</value>
      </property>
      
      <property>
          <name>yarn.resourcemanager.fs.state-state.uri</name>
          <value>/home/companion_tazo/hdfs-data/hadoop/data/yarn/rmstore</value>
      </property>
      
      <property>
      		<name>yarn.resourcemanager.hostname</name>
      		<value>hadoopnode01</value>
      </property>
      
      <property>
      		<name>yarn.web-proxy.address</name>
      		<value>0.0.0.0:8090</value>
      </property>
      
      <property>
      		<name>yarn.nodemanager.log-dirs</name>
      		<value>/home/companion_tazo/hdfs-data/hadoop/data/yarn/logs</value>
      </property>

- uri

  - **통합 자원 식별자**(Uniform Resource Identifier, **URI**)는 인터넷에 있는 자원을 나타내는 유일한 주소이다

- 집에있는 데탑에 깔아보았는데 log와 local은 자동으로 생성되나.

- rmstore는 생성이 안됨.

  

- 얀을 쓰게 되면 기존에 사용 되던 하둡의 셔플기능을 사용할 수가 없어서.

- 얀한테 셔플을 해야한다고 알려줘야한다.

- 리소스 매니저의 상태 정보를 rmstore에 저장한다.

- 호스트 네임을 정해주고 그 외 것들이 접속 할 수 있게 해준다.

- 얀의 로그는 logs에 모두 저장 된다.



- 포맷 단계 (처음 쓰기 때문에)
  - .bashrc에 추가하기.
    - 일단 하면 안된다. 아래 문장은.
    - export HADOOP_HOME=/home/companion_tazo/hadoop-2.7.2
  - namenode format
  - hadoop으로 가서 
  - bin/hdfs namenode -format를 실행한다.

- sbin (Script bin)
  - sbin/start-dfs.sh
  - 각 노드들이 시작된걸 확인.
  - 안되면 stop-dfs.sh 해보고 그래도 안되면 원인 찾기
  - 잘 됐다면 jps로 조회?해보기.
  - sbin/start-yarn.sh
  - sbin/yarn-daemon.sh start proxyserver
  - sbin/mr-jobhistory-daemon.sh start historyserver
    - 3. 버전은
         - bin/mapred historyserver start&
  - **서비스 죽이는 법**
  - sbin/mr-jobhistory-daemon.sh stop historyserver
  - sbin/stop-yarn.sh
  - sbin/stop-dfs.sh

- 그리고 바깥에서 볼수잇게 하기 위해 방화벽 포트 설정에서
- 19888, 50070, 8088을 열어준 뒤
- 버추얼 박스 centos네트워크에서 각 각 포트 포워딩을 해준다.
- 그럼 바깥 os에서 접속이 가능하다.



- 그리고 하둡의 실행문은
- bin/hdfs dfs - 이렇게 써야한다.
- 그런데 오류가 뜬다. 뜨는 이유는 유저 지정이 안되어있기 때문.
- 1. bin/hdfs dfs -mkdir /user
- 2. bin/hdfs dfs -mkdir /user/companion_tazo를 만들어주면 된다.
- 그러면 하둡 파일 시스템의 명령어를 쓸 수 있다.



- 하둡에 cd명령어는 없다. 
- 외부에서 바라봐야하기 때문에 없다.





## 하둡을 써보자

### 데이터 블럭 생성해보기.

- bin/hdfs dfs -mkdir word-input

- bin/hdfs dfs -put etc/hadoop/hadoop-env.sh word-input
- word-input 파일을 만들었고 똑같은게 데이터 노드 2군데로 퍼지게 된다.



### wordcount 사용해보기

- bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar +

  \+ wordcount -> 워드 카운트를 쓸거다

  \+ word-input -> 워드 인풋 폴더의 내용을

  \+ word-output ->워드 아웃폴더에 넣는다.













- **scp -r**

  - **secure copy로 다 복사하여 각각의 노드로 복사할 수 있다.**

  - **-r 저 경로 끝 안에 있는 디렉토리까지 모두 복사한다는 것.**

  - **scp -r /home/companion_tazo/hadoop/etc/hadoop** 

    **hadoopnode02:/home/companion_tazo/ hadoop/etc/hadoop**

  - **조건은 각 기기들이 ssh로 연결되어있어야 함.**

  



##### : .,$d

현재 라인부터 마지막라인 까지 다 지우기.

##### :se paste모드

- 복사할 때 사용하면 자동 띄어쓰기를 막고 복사할 수 있다.







