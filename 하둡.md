# Hadoop

- 여러 군데 흩어져 있는 파일들을 같은 곳에 있는 것처럼 보여주는 것, 또는 다루는 것.

## HDFS

- 하둡 파일 시스템
- 저사양 서버를 이용하여 스토리지를 구성할 수 있음.
- 트랜잭션이 중요한 경우 적합하지 않음, 배치 처리용
- 대규모 데이터를 저장 배치로 처리하는 경우 적합.

### 목표

1. 장애복구
   1. 빠른 시간내에 장애 감지 및 대처
   2. 복제 데이터를 이용한 데이터 유실 방지
2. 스트리밍 방식의 데이터 접근
   1. 클라이언트의 요청을 빠른 시간내에 처리보다는 동일한 시간내에 더 많은 데이터를 처리
3. 대용량 데이터 저장
   1. 높은 데이터 전송 대역폭과 하나의 클러스터에서 수백 대의 노드를 지원할 수 있음.
   2. 하나의 인스턴스에서 수백만개 이상의 파일을 지원
4. 데이터 무결성
   1. 한 번 저장한 데이터는 수정할 수 없고 읽기만 가능
   2. 이동 삭제 복사 가능
   3. 2.0부터 append 기능 지원



### 하둡 설치 방식

독립실행

- 하둡의 기본 실행 모드
- 분산 환경 테스트 불가

가상 분산 

- 기계한대로 여러대 인척 할 수 있다.
- 학습용

완전 분산

- 실제 서비스 용



### 맵 리듀스 연산

### 하둡 에코시스템과 Yarn

- 자원을 효율적으로 쓰기 위해 개발 됨.
- 참고 블로그
- https://nive.tistory.com/?page=12



### 호스트 네임에 ' _ ' 사용금지



### yum을 사용해서 프로그램 설치











## 설치 과정

### 1. 구글의 프로토콜 버퍼

- 네임노드와 데이터간의 통신을 할 때 사용한다.
- 직렬화.
- https://github.com/protocolbuffers/protobuf/releases/download/v2.5.0/protobuf-2.5.0.tar.gz
- 하둡은 2.5 버전 지원.
- su의 권한으로 /usr/local에 파일을 받고 압축을 푼다.
- 압축 푼 파일 안에 Makefile을 확인해보고
- make 시킨다. -> 설치단계
- 컴파일 단계.

- make install
- protoc --version 확인
- libprotoc 2.5.0 -> 출력확인.

### 2.  hadoop 설치

- https://hadoop.apache.org/
- all release에 가서 2.7.2를 받았다. 
- 링크 주소 복사.
- 하둡의 업데이트 속도를 에코 시스템이 따라 잡지 못해서 예전 버전으로 사용.
- 사용자 계정으로 간뒤 홈 디렉토리에 wget 주소 붙여넣기

### 3. hadoopnode 설정

- sudo /etc/hosts
  - 각 기기에 해당하는 node네이밍을 해준다.
  - 127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
    ::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
    **10.0.2.15   hadoopnode01**
    **10.0.2.15   hadoopnode02**
    **10.0.2.15   hadoopnode03**
    **10.0.2.15   hadoopnode04**

### 4. java 셋팅

- jdk 1.8.0_262 설치 확인 없으면 업데이트 해야함.

- jdk 개발자 버전 받기

  - sudo yum install java-1.8.0-openjdk-devel.x86_64

- jps 

  - 자바프로세스를 찾는 툴
  - JVM Process Status tool

- cd로 가서 .bashrc에서 자바 환경변수 설정추가

  - export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.262.b10-0.el7_8.x86_64/
  - 자식 프로세스들은 위의 익스포트 설정을 사용해야한다.
  - export PATH=$PATH:$JAVA_HOME/bin 
  - export CLASS_PATH=.:$JAVA_HOME/lib/tools.jar

- #### 모든 서버(기기)에 다 해야한다.

### 5. 하둡 셋팅

- .bashrc
  - export HADOOP_HOME=/home/companion_tazo/hadoop-2.7.2



### 6. ssh 셋팅

- sudo vi /etc/ssh/sshd_config
  - Port 22를 #을 없애서 열어준다.

##### 방화벽에서 포트 열어주는 법.

-  sudo firewall-cmd --permanent --zone=public --add-port=22/tcp



